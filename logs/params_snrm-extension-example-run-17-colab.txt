BASE_PATH=
BATCH_SIZE=32
BATCH_SIZE_DOCUMENTS=32
DICT_FILE_NAME=data/tokens/tokens_lowered_2019-12-28_001150_min_10.txt
DICT_MIN_FREQ=20
DOCUMENT_COLLECTION_FILE=data/document_collection/collection.air-subset.tsv
DROPOUT_PARAMETER=0.8
EMB_DIM=300
EVALUATION_QUERY_FILE=data/evaluation/queries.air-subset.tsv
EVALUATION_RESULT_CANDIDATE_FILE_PREFIX=results/evaluation_candidate_
EXPERIMENT_MODE=False
HIDDEN_1=50
HIDDEN_2=50
HIDDEN_3=5000
HIDDEN_4=-1
HIDDEN_5=-1
INDEX_PATH=index/
LEARNING_RATE=0.0001
LOG_PATH=tf-log/
MAX_DOC_LEN=103
MAX_Q_LEN=10
MODEL_PATH=model/
NUM_DOCUMENT_BATCHES=18000
NUM_EVALUATION_QUERIES=1000
NUM_RETRIEVAL_DOCUMENTS_PER_QUERY=100
NUM_TRAIN_STEPS=25000
NUM_VALID_STEPS=1000
PRE_TRAINED_EMBEDDING_FILE_NAME=data/embeddings/glove.42B.300d.txt
REGULARIZATION_TERM=5e-06
RESULT_PATH=results/
RUN_NAME=snrm-extension-example-run-17-colab
SAVE_SNAPSHOT_EVERY_N_STEPS=10000
TRAINING_DATA_TRIPLES_FILE=data/training_data/triples.train.small.tsv
VALIDATE_EVERY_N_STEPS=5000
VALIDATION_DATA_TRIPLES_FILE=data/training_data/triples.valid.tsv

Running with TensorFlow version: 1.4.0

Python System information: 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) 
[GCC 7.3.0]


